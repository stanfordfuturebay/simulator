{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generates Mobility file for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')\n",
    "    \n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import copy\n",
    "import scipy as sp\n",
    "import math\n",
    "import seaborn\n",
    "import pickle\n",
    "import warnings\n",
    "import os\n",
    "import random\n",
    "\n",
    "from lib.mobilitysim import MobilitySimulator\n",
    "from lib.town_data import generate_population, generate_sites, assign_work_sites, compute_distances\n",
    "from lib.town_maps import MapIllustrator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings for synthetic mobility data generation\n",
    "\n",
    "Import __one__ `town_settings` file. The following variables will be imported by the `import *` command\n",
    "* `town_name`\n",
    "* `population_path`\n",
    "* `sites_path`\n",
    "* `bbox`\n",
    "* `population_per_age_group`\n",
    "* `region_population`\n",
    "* `town_population`\n",
    "* `daily_tests_unscaled`\n",
    "* `household_info`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lib.settings.town_settings_kaiserslautern import *\n",
    "# from lib.settings.town_settings_ruedesheim import *\n",
    "# from lib.settings.town_settings_tirschenreuth import *\n",
    "# from lib.settings.town_settings_tubingen import *\n",
    "from lib.settings.town_settings_sanfrancisco import *\n",
    "\n",
    "# from lib.settings.town_settings_lausanne import *\n",
    "# from lib.settings.town_settings_locarno import *\n",
    "# from lib.settings.town_settings_lucerne import *\n",
    "# from lib.settings.town_settings_jura import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsampling factor of population and sites\n",
    "downsample = 100\n",
    "\n",
    "# Country for different age groups\n",
    "country = 'US' # 'GER', 'CH'\n",
    "\n",
    "# Set the population generation mode.\n",
    "# 3 options available: custom | random | heuristic\n",
    "population_by = 'custom'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nothing should be changed below\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Town details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample population \n",
    "population_per_age_group = np.round(\n",
    "    population_per_age_group * (town_population / (downsample * region_population))).astype('int').tolist()\n",
    "\n",
    "print(f'Population per age group: {population_per_age_group}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_essential=True\n",
    "if model_essential == True:\n",
    "    '''Hack: Must be changed if want to model essential workers not in SF'''\n",
    "    from lib.settings.town_settings_sanfrancisco import _essential_distribution, _worker_mobility\n",
    "\n",
    "    # proportion of total population that are essential workers\n",
    "    essential_to_total_ratio = 0.2\n",
    "    \n",
    "    # which worker types to include (0:education, 1:office, 2:retail stores, 3:social, 4:supermarket)\n",
    "    incl_worker_types = [0,1,2,3,4]\n",
    "        \n",
    "    essential_distribution = _essential_distribution()\n",
    "    num_essential_workers = np.floor(sum(population_per_age_group)*essential_to_total_ratio).astype('int').tolist()\n",
    "    num_essential_per_age_group = np.floor(num_essential_workers * essential_distribution).astype('int')\n",
    "    essential_prop_per_age_group = np.divide((num_essential_per_age_group),(population_per_age_group))   \n",
    "\n",
    "    strFormat = len(essential_prop_per_age_group) * '{:.2%} '\n",
    "    print(f'Proportion of age groups that are essential workers:\\n {strFormat.format(*essential_prop_per_age_group)}')\n",
    "    print(f'Essential workers per age group:\\n {num_essential_per_age_group}')\n",
    "    print(f'Proportion of essential workers to total: {float((num_essential_per_age_group).sum())/sum(population_per_age_group):.3%}')\n",
    "else:\n",
    "    essential_prop_per_age_group = None\n",
    "    worker_types = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracted site data\n",
    "\n",
    "* `site_loc`: list of site coordinates\n",
    "* `site_type`: list of site category\n",
    "* `site_dict`: helper dictionary with real name (string) of each site category (int)\n",
    "* `density_site_loc`: list of site coordinates of specific type to be based on to generate population density\n",
    "\n",
    "To generate sites of arbitrary sites for a given city, the following function sends queries to OpenStreetMap. In order to use it for additional types of sites, you need to specify queries in the Overpass API format. For more information, check the existing queries in **/lib/data/queries/**, https://wiki.openstreetmap.org/wiki/Overpass_API and http://overpass-turbo.eu/.\n",
    "\n",
    "We separatelly use a query returning all buildings in a town to heuristically generate population density in the next steps if no real population density data is provided. An extra query is required for this purpose and it should be given as a **site_based_density_file** argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block sends queries to OpenStreetMap\n",
    "# Make sure you have a working internet connection\n",
    "# If an error occurs during execution, try executing again \n",
    "# If the call times out or doesn't finish, try restarting your internet connection by e.g. restarting your computer\n",
    "site_files=[]\n",
    "for root,dirs,files in os.walk(sites_path):\n",
    "    for f in files:\n",
    "        if f.endswith(\".txt\") and f != 'buildings.txt':\n",
    "            site_files.append(sites_path+f)\n",
    "\n",
    "site_loc, site_type, site_dict, density_site_loc = generate_sites(bbox=bbox, query_files=site_files,sites_path=sites_path,\n",
    "                                site_based_density_file=sites_path+'buildings.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before downsampling\n",
    "print(site_dict)\n",
    "print('Number of sites: ',np.sum(np.array(site_type)==0),\n",
    "                          np.sum(np.array(site_type)==1),\n",
    "                          np.sum(np.array(site_type)==2),\n",
    "                          np.sum(np.array(site_type)==3),\n",
    "                          np.sum(np.array(site_type)==4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Site visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ill = MapIllustrator()\n",
    "# sitemap = ill.sites_map(bbox=bbox, site_loc=site_loc, site_type=site_type, site_dict = site_dict, map_name=f'{town_name}_site_distribution')\n",
    "# sitemap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate home location based on various options\n",
    "\n",
    "* `home_loc`: list of home coordinates\n",
    "* `people_age`: list of age category \n",
    "* `home_tile`: list of map tile to which each home belongs\n",
    "* `tile_loc`: list tile center coordinates\n",
    "\n",
    "The following three options generate a population distribution across a geographical area consisting of tiles (square boxes) of specific resolution. More information about tile sizes can be found in https://wiki.openstreetmap.org/wiki/Zoom_levels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if region_population == town_population:\n",
    "    tile_level = 15\n",
    "else:\n",
    "    tile_level = 16\n",
    "\n",
    "if population_by == 'custom':\n",
    "    # generate population across tiles based on density input\n",
    "    print('Tile level: ', tile_level)\n",
    "    home_loc, people_age, home_tile, tile_loc, people_household, worker_types = generate_population(\n",
    "        density_file=population_path, bbox=bbox,\n",
    "        population_per_age_group=population_per_age_group, \n",
    "        household_info=household_info, tile_level=tile_level, seed=42,\n",
    "        essential_prop_per_age_group=essential_prop_per_age_group,\n",
    "        incl_worker_types=incl_worker_types)\n",
    "    \n",
    "elif population_by == 'random':\n",
    "    # generate population across tiles uniformly at random\n",
    "    home_loc, people_age, home_tile, tile_loc, people_household, worker_types = generate_population(\n",
    "        bbox=bbox, population_per_age_group=population_per_age_group,\n",
    "        tile_level=16, seed=42,\n",
    "        essential_prop_per_age_group=essential_prop_per_age_group,\n",
    "        incl_worker_types=incl_worker_types)\n",
    "\n",
    "elif population_by == 'heuristic':\n",
    "    # generate population across tiles proportional to buildings per tile\n",
    "    home_loc, people_age, home_tile, tile_loc, people_household, worker_types = generate_population(\n",
    "        bbox=bbox, density_site_loc=density_site_loc,\n",
    "        population_per_age_group=population_per_age_group, tile_level=16, seed=42,\n",
    "        essential_prop_per_age_group=essential_prop_per_age_group,\n",
    "        incl_worker_types=incl_worker_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Num essential workers: {(np.array(worker_types)!=-1).sum()}/{len(worker_types)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_household, counts_household = np.unique(people_household, return_counts=True)\n",
    "plt.hist(counts_household,bins=range(1,9),align='left',rwidth=0.5)\n",
    "plt.xlabel('Household Size')\n",
    "plt.ylabel('Number of Households')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "household_loc = []\n",
    "household_loc_dict = {}\n",
    "for i,ind in enumerate(people_household):\n",
    "    household_loc_dict[ind] = home_loc[i]\n",
    "for i in range(len(household_loc_dict)):\n",
    "    household_loc.append(household_loc_dict[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Home visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# homemap = ill.population_map(bbox=bbox, home_loc=home_loc, map_name=f'{town_name}_population_distribution')\n",
    "# homemap # zoom in to see details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Social Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "edges_out = 5\n",
    "num_colleages = 10 # used in mobilitysim for adding colleages to social graph\n",
    "num_people = len(people_age)\n",
    "friendships = [random.sample(range(num_people), 2) for i in range(num_people * edges_out)]\n",
    "social_graph = nx.Graph()\n",
    "social_graph.add_nodes_from(range(num_people))\n",
    "social_graph.add_edges_from(friendships)\n",
    "num_friends = [social_graph.degree[i] for i in range(num_people)]\n",
    "print('Number of edges: ', social_graph.number_of_edges())\n",
    "print('Max friends: ', max(num_friends))\n",
    "print('Min friends: ', min(num_friends))\n",
    "plt.hist(num_friends,bins=20)\n",
    "print(np.mean(num_friends),np.std(num_friends))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home Gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refuse_gathering_rate = 0.3\n",
    "gather_max_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downsample sites as given by settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_downsample = downsample\n",
    "\n",
    "if site_downsample > 1:\n",
    "#     np.random.seed(42)\n",
    "#     # downsample sites like populatoin\n",
    "#     idx = np.random.choice(len(site_loc), size=int(len(site_loc) / site_downsample), \n",
    "#                            replace=False, p=np.ones(len(site_loc)) / len(site_loc))\n",
    "\n",
    "#     site_loc, site_type = np.array(site_loc)[idx].tolist(), np.array(site_type)[idx].tolist()\n",
    "\n",
    "    # Zihan: new downsampling method so that each type is downsampled by the same value\n",
    "    site_loc_downsampled = []\n",
    "    site_type_downsampled = []\n",
    "    for i in range(len(site_dict)):\n",
    "        curr_type_all = np.zeros(len(site_type))\n",
    "        curr_type_all[np.array(site_type)==i] = 1\n",
    "        idx = np.random.choice(len(site_type), size=int(np.sum(np.array(site_type)==i) / site_downsample), \n",
    "                               replace=False, p=curr_type_all / np.sum(np.array(site_type)==i))\n",
    "        site_loc_downsampled = site_loc_downsampled + np.array(site_loc)[idx].tolist()\n",
    "        site_type_downsampled = site_type_downsampled + np.array(site_type)[idx].tolist()\n",
    "    site_loc = site_loc_downsampled\n",
    "    site_type = site_type_downsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Append homes to sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No downsampling for home loc\n",
    "people_house_site = [ind + len(site_type) for ind in people_household] # site index of people's household\n",
    "site_loc += household_loc\n",
    "site_type += [len(site_dict)]*len(household_loc)\n",
    "site_dict[len(site_dict)] = 'home'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of sites: ', len(site_loc))\n",
    "print(f'Site types:      ', site_dict)\n",
    "print('Number of sites: ',np.sum(np.array(site_type)==0),\n",
    "                          np.sum(np.array(site_type)==1),\n",
    "                          np.sum(np.array(site_type)==2),\n",
    "                          np.sum(np.array(site_type)==3),\n",
    "                          np.sum(np.array(site_type)==4),\n",
    "                          np.sum(np.array(site_type)==5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assign essential work sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worker_work_sites = assign_work_sites(worker_types,site_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute pairwise distances between all tile centers and all sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_site_dist = compute_distances(site_loc, tile_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify synthetic mobility patterns\n",
    "\n",
    "Here we specify the patterns of mobility used for generating the synthetic traces based on the above home and site locations. Note that this is a general framework and can by arbitrarilty extended to any desired site numbers or types. See below for an example used in the first version of our paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.g. line 0 corresponds to age 0-4 in Germany\n",
    "# a lot of eduction (kindergarden), some social, no public transport, no office, no supermarket\n",
    "# the age groups are chosen to match the age groups used in case data by national authorities\n",
    "# GERMANY\n",
    "if country == 'GER':\n",
    "    mob_rate_per_age_per_type = [\n",
    "        [5, 1, 0, 0, 0], # 0-4\n",
    "        [5, 2, 3, 0, 0], # 5-14\n",
    "        [2, 2, 3, 3, 1], # 15-34\n",
    "        [0, 2, 1, 5, 1], # 35-59\n",
    "        [0, 3, 2, 0, 1], # 60-79\n",
    "        [0, 2, 1, 0, 1]]  # 80+\n",
    "    dur_mean_per_type = [2, 1.5, 0.2, 2, 0.5]\n",
    "    variety_per_type = [1, 10, 5, 1, 2]\n",
    "\n",
    "# SWITZERLAND\n",
    "elif country == 'CH':\n",
    "    mob_rate_per_age_per_type = [\n",
    "       [5, 1, 0, 0, 0], # 0-9\n",
    "       [5, 2, 3, 0, 0], # 10-19\n",
    "       [2, 2, 3, 3, 1], # 20-29\n",
    "       [2, 2, 3, 3, 1], # 30-39\n",
    "       [0, 2, 1, 5, 1], # 40-49\n",
    "       [0, 2, 1, 5, 1], # 50-59\n",
    "       [0, 3, 2, 0, 1], # 60-69\n",
    "       [0, 3, 2, 0, 1], # 70-79\n",
    "       [0, 2, 1, 0, 1]] # 80+\n",
    "    dur_mean_per_type = [2, 1.5, 0.2, 2, 0.5]\n",
    "    variety_per_type = [1, 10, 5, 1, 2]\n",
    "    \n",
    "elif country == 'US':\n",
    "    #  {0: 'education', 1: 'office', 2: 'retail', 3: 'social', 4: 'supermarket'}\n",
    "#     mob_rate_per_age_per_type = [\n",
    "#          [5,    0,    0, 0,   0,   0.5],    # 0-5\n",
    "#          [5,    0,    0, 0,   0,   0.5],    # 5-14\n",
    "#          [5,    0, 1.55, 3.6, 0.22,0.5], # 15-19\n",
    "#          [1.48, 3.52, 1.44, 3.6, 0.21,0.5], # 20-24\n",
    "#          [0,    5, 1.87,    3.6, 0.27,0.5], # 25-44\n",
    "#          [0,    5, 2.46,    3.6, 0.36,0.5], # 45-59\n",
    "#          [0,    0, 2.40,    3.6, 0.35,0.5], # 60-79\n",
    "#          [0,    0, 2.43,    3.6, 0.35,0.5]] # 80+\n",
    "    mob_rate_per_age_per_type = [ # calculated with updated Safegraph data in the week 2020-02-24 to 2020-03-01\n",
    "         [5,    0,    0, 0,   0,   0],    # 0-5\n",
    "         [5,    0,    0, 0,   0,   0.5],    # 5-14\n",
    "         [5,    0, 1.16, 2.30, 0.22,0.5], # 15-19\n",
    "         [1.48, 3.52, 1.16, 2.30, 0.20,0.5], # 20-24\n",
    "         [0,    5, 1.16,    2.30, 0.26,0.5], # 25-44\n",
    "         [0,    5, 1.16,    2.30, 0.35,0.5], # 45-59\n",
    "         [0,    0, 1.16,    2.30, 0.34,0.5], # 60-79\n",
    "         [0,    0, 1.16,    2.30, 0.34,0.5]] # 80+\n",
    "\n",
    "#     dur_mean_per_type = [5.0, 5.0, 0.55, 0.64, 0.4, 3.0]\n",
    "    dur_mean_per_type = [5.0, 5.0, 0.70, 0.83, 0.55, 3.0] # calculated with updated Safegraph data in the week 2020-02-24 to 2020-03-01\n",
    "    variety_per_type = [1, 1, 10, 10, 2, 1] # variety_per_type for home sites does not matter\n",
    "    \n",
    "    if model_essential==True:\n",
    "        wtype='-'.join([str(w) for w in incl_worker_types])\n",
    "#         essential_mob_rate_per_type, essential_dur_mean_per_type, essential_variety_per_type = mob_rate_per_age_per_type[0], dur_mean_per_type, variety_per_type\n",
    "#         essential_mob_rate_per_type, essential_dur_mean_per_type, essential_variety_per_type = _essential_mobility(wtype)\n",
    "        worker_mob_rate_per_types, worker_dur_mean_per_types, worker_variety_per_types = _worker_mobility()\n",
    "        print(f\"MRPAPT: {mob_rate_per_age_per_type}, DMPT: {dur_mean_per_type}, VPT: {variety_per_type}\")\n",
    "        print(f\"WMRPT: {worker_mob_rate_per_types}, WDMRT: {worker_dur_mean_per_types}, WVPT: {worker_variety_per_types}\")\n",
    "    else:\n",
    "        wtype='noness'\n",
    "        essential_mob_rate_per_type, essential_dur_mean_per_type, essential_variety_per_type = None, None, None\n",
    "else:\n",
    "    raise ValueError('Invalid country code.')\n",
    "    \n",
    "# convert to average visits per hour per week, to be compatible with simulator\n",
    "mob_rate_per_age_per_type = np.divide(np.array(mob_rate_per_age_per_type), (24.0 * 7))\n",
    "worker_mob_rate_per_types = np.divide(np.array(worker_mob_rate_per_types),(24.0*7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set `delta`; the setting for delta is explained in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time horizon\n",
    "delta  = 4.6438 # as set by distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Population (by Age): ', population_per_age_group)\n",
    "print('Sites (by type):     ',  [(np.array(site_type) == i).sum() for i in range(len(mob_rate_per_age_per_type[0]))])\n",
    "\n",
    "print('Total:', sum(population_per_age_group), len(site_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save arguments for the class object instantiation to be able to initiate `MobilitySimulator` on the fly during inference. That is more efficient than pickling in some cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = dict(\n",
    "    home_loc=home_loc, \n",
    "    people_age=people_age, \n",
    "    site_loc=site_loc, \n",
    "    num_people_unscaled=town_population,\n",
    "    region_population=region_population,\n",
    "    site_type=site_type, \n",
    "    site_dict=site_dict, \n",
    "    downsample=downsample,\n",
    "    mob_rate_per_age_per_type=mob_rate_per_age_per_type,\n",
    "    daily_tests_unscaled=daily_tests_unscaled, \n",
    "    dur_mean_per_type=dur_mean_per_type, \n",
    "    variety_per_type=variety_per_type, \n",
    "    delta=delta,\n",
    "    home_tile=home_tile, \n",
    "    tile_site_dist=tile_site_dist, \n",
    "    people_household=people_household,\n",
    "    worker_types=worker_types,\n",
    "    worker_mob_rate_per_types=worker_mob_rate_per_types,\n",
    "    worker_dur_mean_per_types=worker_dur_mean_per_types,\n",
    "    worker_work_sites=worker_work_sites,\n",
    "    social_graph = social_graph,\n",
    "    num_colleages = num_colleages,\n",
    "    people_house_site=people_house_site,\n",
    "    refuse_gathering_rate=refuse_gathering_rate,\n",
    "    gather_max_size=gather_max_size)\n",
    "\n",
    "if model_essential==False:\n",
    "    outfile = f'lib/mobility/{town_name}_settings_{downsample}.pk'\n",
    "else:\n",
    "    outfile = f'lib/mobility/{town_name}_settings_{downsample}_type{wtype}_{int(essential_to_total_ratio*100)}pct_social_graph_homesite_new_mob.pk'\n",
    "with open(outfile, 'wb') as fp:\n",
    "    pickle.dump(kwargs, fp)\n",
    "print(f'Saved mobility settings to {outfile}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create mobility traces as above, or comment in the last section below to specify fully artifial traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"lib/mobility/San_Francisco_settings_100_type0-1-2-3_20pct_social_graph_homesite.pk\", 'rb') as fp:\n",
    "    kwargs = pickle.load(fp)\n",
    "mob = MobilitySimulator(**kwargs)\n",
    "mob.verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_time = 17 * 24.0 # e.g. 17 days\n",
    "%time mob.simulate(max_time=max_time, seed=12345)\n",
    "# %time mob.to_pickle(f'tu_mobility_{downsample_population}_{downsample_sites}.pk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4915 in social_graph.adj[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laura Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _num_interactions(contact_list):\n",
    "#     interactions = 0\n",
    "#     for contact in contact_list:\n",
    "#         interactions += \n",
    "\n",
    "def num_contacts_and_interactions(mob):\n",
    "    num_contacts = np.array([len(mob.contacts[i]) for i in mob.contacts])\n",
    "    num_interactions = np.array([sum([len(mob.contacts[i][j]) for j in mob.contacts[i]]) for i in mob.contacts])\n",
    "    return num_contacts, num_interactions\n",
    "\n",
    "num_contacts, num_interactions = num_contacts_and_interactions(mob)\n",
    "print(num_contacts, num_interactions)\n",
    "print(np.unique(num_interactions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(list(mob.contacts[3].keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mob.contacts[3].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mob.contacts[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "# len(mob.contacts[3][841])\n",
    "for person_i in mob.contacts:\n",
    "    i_contacts = mob.contacts[person_i]\n",
    "    for person_j in i_contacts:\n",
    "        inter = i_contacts[person_j]\n",
    "        if len(inter)>1:\n",
    "            pdb.set_trace()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def household_size(mob):\n",
    "    people_household = mob.people_household\n",
    "    unique_household, counts_household = np.unique(people_household, return_counts=True)\n",
    "    f = lambda x: counts_household[x]\n",
    "    household_size = f(people_household)\n",
    "    return household_size\n",
    "    # plt.hist(household_size,bins=range(1,9),align='left',rwidth=0.5)\n",
    "    # plt.xlabel('Household Size')\n",
    "    # plt.ylabel('Number of Households')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(household_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
